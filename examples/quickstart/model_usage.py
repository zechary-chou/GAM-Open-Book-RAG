#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GAM Model Usage Example

å±•ç¤ºå¦‚ä½•ä½¿ç”¨ä¸åŒçš„ LLM æ¨¡å‹ï¼ˆOpenAI API æˆ–æœ¬åœ° VLLMï¼‰ä¸ GAM æ¡†æ¶ã€‚
"""

import os

from gam import (
    MemoryAgent,
    OpenAIGenerator,
    OpenAIGeneratorConfig,
    InMemoryMemoryStore,
    InMemoryPageStore,
)


def openai_api_example():
    """OpenAI API æ¨¡å‹ä½¿ç”¨ç¤ºä¾‹"""
    print("=== OpenAI API æ¨¡å‹ç¤ºä¾‹ ===\n")
    
    # 1. é…ç½® OpenAI Generator
    gen_config = OpenAIGeneratorConfig(
        model_name="gpt-4o-mini",  # æˆ– "gpt-4", "gpt-3.5-turbo"
        api_key=os.getenv("OPENAI_API_KEY"),
        temperature=0.3,
        max_tokens=1000
    )
    
    # 2. åˆ›å»º Generator
    generator = OpenAIGenerator.from_config(gen_config)
    
    # 3. åˆ›å»ºå­˜å‚¨
    memory_store = InMemoryMemoryStore()
    page_store = InMemoryPageStore()
    
    # 4. åˆ›å»º MemoryAgent
    memory_agent = MemoryAgent(
        generator=generator,
        memory_store=memory_store,
        page_store=page_store
    )
    
    # 5. æµ‹è¯•ç®€å•æ–‡æ¡£
    documents = [
        "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é›†ã€‚",
        "æ·±åº¦å­¦ä¹ ä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œã€‚",
        "è‡ªç„¶è¯­è¨€å¤„ç†ä¸“æ³¨äºäººç±»è¯­è¨€ç†è§£ã€‚"
    ]
    
    print(f"æ­£åœ¨å¤„ç† {len(documents)} ä¸ªæ–‡æ¡£...")
    for doc in documents:
        memory_agent.memorize(doc)
    
    memory_state = memory_store.load()
    print(f"âœ… æ„å»ºäº† {len(memory_state.abstracts)} ä¸ªè®°å¿†æ‘˜è¦\n")
    
    return True


def custom_api_endpoint_example():
    """è‡ªå®šä¹‰ API ç«¯ç‚¹ç¤ºä¾‹ï¼ˆå…¼å®¹ OpenAI çš„ç¬¬ä¸‰æ–¹æœåŠ¡ï¼‰"""
    print("=== è‡ªå®šä¹‰ API ç«¯ç‚¹ç¤ºä¾‹ ===\n")
    
    # 1. é…ç½®è‡ªå®šä¹‰ç«¯ç‚¹çš„ OpenAI Generator
    gen_config = OpenAIGeneratorConfig(
        model_name="gpt-4o-mini",
        api_key=os.getenv("OPENAI_API_KEY"),
        base_url="https://your-custom-endpoint.com/v1",  # è‡ªå®šä¹‰ç«¯ç‚¹
        temperature=0.3
    )
    
    # 2. åˆ›å»º Generator
    generator = OpenAIGenerator.from_config(gen_config)
    
    # 3. åˆ›å»ºå­˜å‚¨
    memory_store = InMemoryMemoryStore()
    page_store = InMemoryPageStore()
    
    # 4. åˆ›å»º MemoryAgent
    memory_agent = MemoryAgent(
        generator=generator,
        memory_store=memory_store,
        page_store=page_store
    )
    
    print("âœ… é…ç½®äº†è‡ªå®šä¹‰ API ç«¯ç‚¹")
    print(f"   ç«¯ç‚¹: {gen_config.base_url}")
    print(f"   æ¨¡å‹: {gen_config.model_name}\n")
    
    return True


def vllm_local_model_example():
    """VLLM æœ¬åœ°æ¨¡å‹ä½¿ç”¨ç¤ºä¾‹"""
    print("=== VLLM æœ¬åœ°æ¨¡å‹ç¤ºä¾‹ ===\n")
    
    try:
        from gam import VLLMGenerator, VLLMGeneratorConfig
        
        # 1. é…ç½® VLLM Generator
        gen_config = VLLMGeneratorConfig(
            model_name="Qwen2.5-7B-Instruct",  # æœ¬åœ°æ¨¡å‹åç§°
            api_key="empty",  # VLLM é€šå¸¸ä½¿ç”¨ "empty" ä½œä¸º API Key
            base_url="http://localhost:8000/v1",  # vLLM æœåŠ¡å™¨åœ°å€
            temperature=0.7,
            max_tokens=512
        )
        
        # 2. åˆ›å»º Generator
        generator = VLLMGenerator.from_config(gen_config)
        
        # 3. åˆ›å»ºå­˜å‚¨
        memory_store = InMemoryMemoryStore()
        page_store = InMemoryPageStore()
        
        # 4. åˆ›å»º MemoryAgent
        memory_agent = MemoryAgent(
            generator=generator,
            memory_store=memory_store,
            page_store=page_store
        )
        
        # 5. æµ‹è¯•ç®€å•æ–‡æ¡£
        documents = [
            "AI is artificial intelligence.",
            "ML is machine learning.",
            "DL is deep learning."
        ]
        
        print(f"æ­£åœ¨å¤„ç† {len(documents)} ä¸ªæ–‡æ¡£...")
        for doc in documents:
            memory_agent.memorize(doc)
        
        memory_state = memory_store.load()
        print(f"âœ… æ„å»ºäº† {len(memory_state.abstracts)} ä¸ªè®°å¿†æ‘˜è¦\n")
        
        return True
        
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
        print("   è¯·å®‰è£…: pip install vllm>=0.6.0")
        return False
    except Exception as e:
        print(f"âŒ æœ¬åœ°æ¨¡å‹é”™è¯¯: {e}")
        print("   æç¤º: å¦‚æœå†…å­˜æœ‰é™ï¼Œå°è¯•ä½¿ç”¨æ›´å°çš„æ¨¡å‹")
        return False


def model_comparison():
    """æ¨¡å‹å¯¹æ¯”è¯´æ˜"""
    print("\n=== æ¨¡å‹é€‰æ‹©æŒ‡å— ===\n")
    
    print("ğŸ“Œ OpenAI API æ¨¡å‹:")
    print("   ä¼˜ç‚¹:")
    print("     âœ… å¿«é€Ÿå¼€å§‹ï¼Œæ— éœ€æœ¬åœ°èµ„æº")
    print("     âœ… å¼ºå¤§çš„æ€§èƒ½å’Œå‡†ç¡®æ€§")
    print("     âœ… è‡ªåŠ¨æ›´æ–°å’Œç»´æŠ¤")
    print("   ç¼ºç‚¹:")
    print("     âŒ éœ€è¦ç½‘ç»œè¿æ¥")
    print("     âŒ æŒ‰ä½¿ç”¨é‡ä»˜è´¹")
    print("     âŒ æ•°æ®å‘é€åˆ°å¤–éƒ¨æœåŠ¡å™¨")
    print()
    
    print("ğŸ“Œ VLLM æœ¬åœ°æ¨¡å‹:")
    print("   ä¼˜ç‚¹:")
    print("     âœ… å®Œå…¨ç¦»çº¿è¿è¡Œ")
    print("     âœ… æ•°æ®éšç§ä¿æŠ¤")
    print("     âœ… æ— ä½¿ç”¨é™åˆ¶")
    print("   ç¼ºç‚¹:")
    print("     âŒ éœ€è¦ GPU èµ„æº")
    print("     âŒ éœ€è¦ä¸‹è½½å’Œç®¡ç†æ¨¡å‹")
    print("     âŒ å¯èƒ½éœ€è¦æ›´å¤šé…ç½®")
    print()
    
    print("ğŸ’¡ å»ºè®®:")
    print("   - å¿«é€ŸåŸå‹å’Œå¼€å‘: ä½¿ç”¨ OpenAI API")
    print("   - ç”Ÿäº§ç¯å¢ƒå’Œéšç§è¦æ±‚: è€ƒè™‘æœ¬åœ° VLLM")
    print("   - å¤§è§„æ¨¡ä½¿ç”¨: æ ¹æ®æˆæœ¬å’Œæ€§èƒ½æƒè¡¡é€‰æ‹©")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("GAM æ¨¡å‹ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    print()
    
    # æ£€æŸ¥ API Key
    has_api_key = bool(os.getenv("OPENAI_API_KEY"))
    
    if not has_api_key:
        print("âš ï¸  æœªæ£€æµ‹åˆ° OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        print("   æŸäº›ç¤ºä¾‹å°†æ— æ³•è¿è¡Œ")
        print("   è®¾ç½®æ–¹æ³•: export OPENAI_API_KEY='your-api-key'\n")
    
    # æµ‹è¯• OpenAI API æ¨¡å‹
    if has_api_key:
        try:
            openai_success = openai_api_example()
        except Exception as e:
            print(f"OpenAI API ç¤ºä¾‹å¤±è´¥: {e}\n")
            openai_success = False
    else:
        print("è·³è¿‡ OpenAI API ç¤ºä¾‹ï¼ˆæœªè®¾ç½® API Keyï¼‰\n")
        openai_success = False
    
    # è‡ªå®šä¹‰ç«¯ç‚¹ç¤ºä¾‹ï¼ˆä»…é…ç½®ï¼Œä¸å®é™…è¿è¡Œï¼‰
    custom_endpoint_success = custom_api_endpoint_example()
    
    # æµ‹è¯• VLLM æœ¬åœ°æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
    print("æ˜¯å¦æµ‹è¯• VLLM æœ¬åœ°æ¨¡å‹ï¼Ÿï¼ˆéœ€è¦ GPU å’Œæ¨¡å‹æ–‡ä»¶ï¼‰")
    print("æ³¨æ„: è¿™å°†ä¸‹è½½å’ŒåŠ è½½å¤§å‹æ¨¡å‹ï¼Œéœ€è¦è¾ƒé•¿æ—¶é—´")
    test_vllm = input("è¾“å…¥ 'yes' ç»§ç»­ï¼Œæˆ–æŒ‰ Enter è·³è¿‡: ").strip().lower()
    
    if test_vllm == 'yes':
        vllm_success = vllm_local_model_example()
    else:
        print("è·³è¿‡ VLLM æœ¬åœ°æ¨¡å‹ç¤ºä¾‹\n")
        vllm_success = False
    
    # æ˜¾ç¤ºæ¨¡å‹å¯¹æ¯”
    model_comparison()
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹æ€»ç»“")
    print("=" * 60)
    if openai_success:
        print("âœ… OpenAI API æ¨¡å‹: é€‚åˆå¿«é€ŸåŸå‹å’Œéƒ¨ç½²")
    if custom_endpoint_success:
        print("âœ… è‡ªå®šä¹‰ç«¯ç‚¹: é€‚åˆä½¿ç”¨å…¼å®¹ OpenAI çš„ç¬¬ä¸‰æ–¹æœåŠ¡")
    if vllm_success:
        print("âœ… VLLM æœ¬åœ°æ¨¡å‹: é€‚åˆéšç§å’Œç¦»çº¿ä½¿ç”¨")
    
    print("\nğŸ’¡ æ ¹æ®ä½ çš„éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ¨¡å‹ç±»å‹ï¼")
    print("\næ›´å¤šä¿¡æ¯:")
    print("  - æŸ¥çœ‹ eval/ ç›®å½•äº†è§£è¯„ä¼°ç¤ºä¾‹")
    print("  - æŸ¥çœ‹ gam/generator/ äº†è§£ç”Ÿæˆå™¨å®ç°")


if __name__ == "__main__":
    main()
