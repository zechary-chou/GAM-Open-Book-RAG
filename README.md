# General Agentic Memory (GAM)

A general memory system for agents, powered by deep-research

[ä¸­æ–‡æ–‡æ¡£](README_CN.md) | English

<h5 align="center"> ğŸ‰ If you like our project, please give us a star â­ on GitHub for the latest update.</h5>

**General Agentic Memory (GAM)** provides a next-generation memory framework for AI agents, combining long-term retention with dynamic reasoning. Following the Just-in-Time (JIT) principle, it preserves full contextual fidelity offline while performing deep research online to build adaptive, high-utility context. With its dual-agent architectureâ€”Memorizer and Researcherâ€”GAM integrates structured memory with iterative retrieval and reflection, achieving state-of-the-art performance across LoCoMo, HotpotQA, LongBench v2, and LongCodeBench benchmarks.

- **Paper**: 
- **Website**: 
- **Documentation**: 
- **YouTube Video**: 

<span id='features'/>

## âœ¨ Key Features

* ğŸ§  **Just-in-Time (JIT) Memory Optimization**
</br> Unlike conventional Ahead-of-Time (AOT) systems, GAM performs intensive Memory Deep Research at runtime, dynamically retrieving and synthesizing high-utility context to meet real-time agent needs.

* ğŸ” **Dual-Agent Architecture: Memorizer & Researcher**
</br> A cooperative framework where the Memorizer constructs structured memory from raw sessions, and the Researcher performs iterative retrieval, reflection, and summarization to deliver precise, adaptive context.

* ğŸš€ **Superior Performance Across Benchmarks**
</br> Achieves state-of-the-art results on LoCoMo, HotpotQA, LongBench v2, and LongCodeBench, surpassing prior systems such as A-MEM, Mem0, and MemoryOS in both F1 and BLEU-1 metrics.

* ğŸ§© **Modular & Extensible Design**
</br> Built to support flexible plug-ins for memory construction, retrieval strategies, and reasoning toolsâ€”facilitating easy integration into multi-agent frameworks or standalone LLM deployments.

* ğŸŒ **Cross-Model Compatibility**
</br> Compatible with leading LLMs such as GPT-4, GPT-4o-mini, and Qwen2.5, supporting both cloud-based and local deployments for research or production environments.

<span id='news'/>

## ğŸ“£ Latest News

- **2025-11**: Released GAM framework with modular evaluation suite
- **2025-11**: Support for HotpotQA, NarrativeQA, LoCoMo, and RULER benchmarks

## ğŸ“‘ Table of Contents

* [âœ¨ Features](#features)
* [ğŸ”¥ News](#news)
* [ğŸ—ï¸ Project Structure](#structure)
* [ğŸ¯ Quick Start](#quick-start)
* [ğŸ”¬ Reproducing Paper Results](#reproduce)
* [ğŸ“– Documentation](#doc)
* [ğŸŒŸ Citation](#cite)
* [ğŸ¤ Community](#community)

<span id='structure'/>

## ğŸ—ï¸ System Architecture

![logo](./assets/GAM-memory.png)

## ğŸ—ï¸ Project Structure

```
general-agentic-memory/
â”œâ”€â”€ gam/                          # Core GAM package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agents/                   # Agent implementations
â”‚   â”‚   â”œâ”€â”€ memory_agent.py      # MemoryAgent - memory construction
â”‚   â”‚   â””â”€â”€ research_agent.py    # ResearchAgent - deep research
â”‚   â”œâ”€â”€ generator/                # LLM generators
â”‚   â”‚   â”œâ”€â”€ openai_generator.py  # OpenAI API generator
â”‚   â”‚   â””â”€â”€ vllm_generator.py    # VLLM local generator
â”‚   â”œâ”€â”€ retriever/                # Retrievers
â”‚   â”‚   â”œâ”€â”€ index_retriever.py   # Index retrieval
â”‚   â”‚   â”œâ”€â”€ bm25.py              # BM25 keyword retrieval
â”‚   â”‚   â””â”€â”€ dense_retriever.py   # Dense semantic retrieval
â”‚   â”œâ”€â”€ prompts/                  # Prompt templates
â”‚   â”œâ”€â”€ schemas/                  # Data models
â”‚   â””â”€â”€ config/                   # Configuration management
â”œâ”€â”€ eval/                         # Evaluation suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ run.py                   # Unified CLI entry
â”‚   â”œâ”€â”€ README.md                # Evaluation documentation
â”‚   â”œâ”€â”€ QUICKSTART.md            # Quick start guide
â”‚   â”œâ”€â”€ datasets/                # Dataset adapters
â”‚   â”‚   â”œâ”€â”€ base.py             # Base evaluation class
â”‚   â”‚   â”œâ”€â”€ hotpotqa.py         # HotpotQA multi-hop QA
â”‚   â”‚   â”œâ”€â”€ narrativeqa.py      # NarrativeQA narrative QA
â”‚   â”‚   â”œâ”€â”€ locomo.py           # LoCoMo conversation memory
â”‚   â”‚   â””â”€â”€ ruler.py            # RULER long-context eval
â”‚   â””â”€â”€ utils/                   # Evaluation utilities
â”‚       â”œâ”€â”€ chunking.py         # Text chunking
â”‚       â””â”€â”€ metrics.py          # Evaluation metrics
â”œâ”€â”€ scripts/                      # Shell scripts
â”‚   â”œâ”€â”€ eval_hotpotqa.sh
â”‚   â”œâ”€â”€ eval_narrativeqa.sh
â”‚   â”œâ”€â”€ eval_locomo.sh
â”‚   â”œâ”€â”€ eval_ruler.sh
â”‚   â””â”€â”€ eval_all.sh
â”œâ”€â”€ examples/                     # Usage examples
â”‚   â””â”€â”€ quickstart/              # Quick start examples
â”‚       â”œâ”€â”€ README.md            # Examples documentation
â”‚       â”œâ”€â”€ basic_usage.py       # Basic usage example
â”‚       â””â”€â”€ model_usage.py       # Model selection example
â”œâ”€â”€ assets/                       # Resource files
â”œâ”€â”€ docs/                         # Documentation
â”œâ”€â”€ setup.py                      # Installation config
â”œâ”€â”€ pyproject.toml               # Modern project config
â”œâ”€â”€ requirements.txt             # Dependencies
â””â”€â”€ README.md                    # This file
```

<span id='quick-start'/>

## ğŸ¯ Quick Start

### ğŸš€ Installation

```bash
# Clone the repository
git clone https://github.com/VectorSpaceLab/general-agentic-memory.git
cd general-agentic-memory

# Install dependencies
pip install -r requirements.txt

# Install the package
pip install -e .
```

### ğŸ’¡ Basic Usage

```python
import os
from gam import (
    MemoryAgent,
    ResearchAgent,
    OpenAIGenerator,
    OpenAIGeneratorConfig,
    InMemoryMemoryStore,
    InMemoryPageStore,
    DenseRetriever,
    DenseRetrieverConfig,
)

# 1. Configure and create generator
gen_config = OpenAIGeneratorConfig(
    model="gpt-4o-mini",
    api_key=os.getenv("OPENAI_API_KEY"),
    temperature=0.3
)
generator = OpenAIGenerator(gen_config)

# 2. Create memory and page stores
memory_store = InMemoryMemoryStore()
page_store = InMemoryPageStore()

# 3. Create MemoryAgent
memory_agent = MemoryAgent(
    generator=generator,
    memory_store=memory_store,
    page_store=page_store
)

# 4. Memorize documents
documents = [
    "Artificial Intelligence is a branch of computer science...",
    "Machine Learning is a subset of AI...",
    "Deep Learning uses neural networks..."
]

for doc in documents:
    memory_agent.memorize(doc)

# 5. Get memory state
memory_state = memory_agent.get_memory_state()
print(f"Built {len(memory_state.events)} memory events")

# 6. Create ResearchAgent for Q&A
retriever_config = DenseRetrieverConfig(
    model_path="BAAI/bge-base-en-v1.5"
)
retriever = DenseRetriever(
    config=retriever_config,
    memory_store=memory_store,
    page_store=page_store
)

research_agent = ResearchAgent(
    generator=generator,
    retriever=retriever
)

# 7. Perform research
result = research_agent.research(
    question="What is the difference between ML and DL?",
    top_k=3
)

print(f"Answer: {result.final_answer}")
```

### ğŸ“š Complete Examples

For detailed examples and advanced usage:
- [`examples/quickstart/basic_usage.py`](./examples/quickstart/basic_usage.py) - Complete workflow with memory building and research
- [`examples/quickstart/model_usage.py`](./examples/quickstart/model_usage.py) - Model selection and configuration
- [`examples/quickstart/README.md`](./examples/quickstart/README.md) - Examples documentation

<span id='reproduce'/>

## ğŸ”¬ How to Reproduce the Results in the Paper

We provide a complete evaluation framework to reproduce the experimental results in the paper.

### Quick Start

```bash
# 1. Prepare datasets
mkdir -p data
# Place your datasets in the data/ directory

# 2. Set environment variables
export OPENAI_API_KEY="your_api_key_here"

# 3. Run evaluations
# HotpotQA
bash scripts/eval_hotpotqa.sh --data-path data/hotpotqa.json

# NarrativeQA
bash scripts/eval_narrativeqa.sh --data-path narrativeqa --max-samples 100

# LoCoMo
bash scripts/eval_locomo.sh --data-path data/locomo.json

# RULER
bash scripts/eval_ruler.sh --data-path data/ruler.jsonl --dataset-name niah_single_1

# Or run all evaluations
bash scripts/eval_all.sh
```

### Using Python CLI

```bash
python -m eval.run \
    --dataset hotpotqa \
    --data-path data/hotpotqa.json \
    --generator openai \
    --model gpt-4 \
    --retriever dense \
    --max-samples 100
```

### Documentation

For complete evaluation documentation:
- [eval/README.md](./eval/README.md) - Evaluation framework guide
- [eval/QUICKSTART.md](./eval/QUICKSTART.md) - Quick start guide

### Supported Datasets

| Dataset | Task Type | Metrics | Documentation |
|---------|-----------|---------|---------------|
| **HotpotQA** | Multi-hop QA | F1 | [View](./eval/datasets/hotpotqa.py) |
| **NarrativeQA** | Narrative QA | F1 | [View](./eval/datasets/narrativeqa.py) |
| **LoCoMo** | Conversation Memory | F1, BLEU-1 | [View](./eval/datasets/locomo.py) |
| **RULER** | Long Context | Accuracy | [View](./eval/datasets/ruler.py) |

<span id='doc'/>

## ğŸ“– Documentation

More detailed documentation is coming soon ğŸš€. Check these resources in the meantime:

- [Examples Documentation](./examples/quickstart/README.md) - Usage examples and tutorials
- [Evaluation Guide](./eval/README.md) - Evaluation framework documentation
- [Quick Start Guide](./eval/QUICKSTART.md) - Quick start for evaluations

<span id='cite'/>

## ğŸ“£ Citation

**If you find this project useful, please consider citing our paper:**

```bibtex
```

<span id='community'/>

## ğŸ¤ Community

### ğŸ¯ Contact Us

- GitHub Issues: [Report bugs or request features](https://github.com/VectorSpaceLab/general-agentic-memory/issues)
- Email: your-email@example.com

### ğŸŒŸ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=VectorSpaceLab/general-agentic-memory&type=Date)](https://star-history.com/#VectorSpaceLab/general-agentic-memory&Date)

### ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit issues or pull requests.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

We thank the authors of the following datasets:
- HotpotQA
- NarrativeQA
- LoCoMo
- RULER

## Disclaimer

This is a research project. Please use it responsibly and ethically.

---

<p align="center">
Made with â¤ï¸ by the GAM Team
</p>
