# General Agentic Memory (GAM)

<p align="center">
  <a href="https://arxiv.org/abs/2511.18423" target="_blank">
    <img src="https://img.shields.io/badge/arXiv-2511.18423-b31b1b?style=for-the-badge&logo=arxiv&logoColor=white" alt="arXiv">
  </a>
  <a href="https://huggingface.co/papers/2511.18423" target="_blank">
    <img src="https://img.shields.io/badge/HuggingFace-Paper-ffcc4d?style=for-the-badge&logo=huggingface&logoColor=black" alt="HuggingFace">
  </a>
</p>

A general memory system for agents, powered by deep-research

[ä¸­æ–‡æ–‡æ¡£](README_CN.md) | English

<h5 align="center"> ğŸ‰ If you like our project, please give us a star â­ on GitHub for the latest update.</h5>

**General Agentic Memory (GAM)** provides a next-generation memory framework for AI agents, combining long-term retention with dynamic reasoning. Following the Just-in-Time (JIT) principle, it preserves full contextual fidelity offline while performing deep research online to build adaptive, high-utility context. With its dual-agent architectureâ€”Memorizer and Researcherâ€”GAM integrates structured memory with iterative retrieval and reflection, achieving state-of-the-art performance across LoCoMo, HotpotQA, RULER, and NarrativeQA benchmarks.

- **Paper**: <a href="[https://arxiv.org/abs/2511.18423](https://arxiv.org/abs/2511.18423)" target="_blank">[https://arxiv.org/abs/2511.18423](https://arxiv.org/abs/2511.18423)</a>
- **Huggingface**: <a href="[https://huggingface.co/papers/2511.18423](https://huggingface.co/papers/2511.18423)" target="_blank">[https://huggingface.co/papers/2511.18423](https://huggingface.co/papers/2511.18423)</a>
<!-- - **Website**: 
- **Documentation**: 
- **YouTube Video**:  -->

<span id='features'/>

## âœ¨ Key Features

* ğŸ§  **Just-in-Time (JIT) Memory Optimization**
</br> Unlike conventional Ahead-of-Time (AOT) systems, GAM performs intensive Memory Deep Research at runtime, dynamically retrieving and synthesizing high-utility context to meet real-time agent needs.

* ğŸ” **Dual-Agent Architecture: Memorizer & Researcher**
</br> A cooperative framework where the Memorizer constructs structured memory from raw sessions, and the Researcher performs iterative retrieval, reflection, and summarization to deliver precise, adaptive context.

* ğŸš€ **Superior Performance Across Benchmarks**
</br> Achieves state-of-the-art results on LoCoMo, HotpotQA, RULER, and NarrativeQA, surpassing prior systems such as A-MEMã€Mem0ã€ MemoryOS and LightMem in both F1 and BLEU-1 metrics.

* ğŸ§© **Modular & Extensible Design**
</br> Built to support flexible plug-ins for memory construction, retrieval strategies, and reasoning toolsâ€”facilitating easy integration into multi-agent frameworks or standalone LLM deployments.

* ğŸŒ **Cross-Model Compatibility**
</br> Compatible with leading LLMs such as GPT-4, GPT-4o-mini, and Qwen2.5, supporting both cloud-based and local deployments for research or production environments.

<span id='news'/>

## ğŸ“£ Latest News

- **2025-11**: Released GAM framework with modular evaluation suite
- **2025-11**: Support for HotpotQA, NarrativeQA, LoCoMo, and RULER benchmarks

## ğŸ“‘ Table of Contents

* [âœ¨ Features](#features)
* [ğŸ”¥ News](#news)
* [ğŸ—ï¸ Project Structure](#structure)
* [ğŸ¯ Quick Start](#quick-start)
* [ğŸ”¬ Reproducing Paper Results](#reproduce)
* [ğŸ“– Documentation](#doc)
* [ğŸŒŸ Citation](#cite)
* [ğŸ¤ Community](#community)

<span id='structure'/>

## ğŸ—ï¸ System Architecture

![logo](./assets/GAM-memory.png)

## ğŸ—ï¸ Project Structure

```
general-agentic-memory/
â”œâ”€â”€ gam/                          # Core GAM package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agents/                   # Agent implementations
â”‚   â”‚   â”œâ”€â”€ memory_agent.py      # MemoryAgent - memory construction
â”‚   â”‚   â””â”€â”€ research_agent.py    # ResearchAgent - deep research
â”‚   â”œâ”€â”€ generator/                # LLM generators
â”‚   â”‚   â”œâ”€â”€ openai_generator.py  # OpenAI API generator
â”‚   â”‚   â””â”€â”€ vllm_generator.py    # VLLM local generator
â”‚   â”œâ”€â”€ retriever/                # Retrievers
â”‚   â”‚   â”œâ”€â”€ index_retriever.py   # Index retrieval
â”‚   â”‚   â”œâ”€â”€ bm25.py              # BM25 keyword retrieval
â”‚   â”‚   â””â”€â”€ dense_retriever.py   # Dense semantic retrieval
â”‚   â”œâ”€â”€ prompts/                  # Prompt templates
â”‚   â”œâ”€â”€ schemas/                  # Data models
â”‚   â””â”€â”€ config/                   # Configuration management
â”œâ”€â”€ eval/                         # Evaluation suite
â”‚   â”œâ”€â”€ hotpotqa_test.py        # HotpotQA evaluation script
â”‚   â”œâ”€â”€ narrativeqa_test.py     # NarrativeQA evaluation script
â”‚   â”œâ”€â”€ locomo_test.py          # LoCoMo evaluation script
â”‚   â””â”€â”€ ruler_test.py           # RULER evaluation script
â”œâ”€â”€ scripts/                      # Shell scripts
â”‚   â”œâ”€â”€ eval_hotpotqa.sh
â”‚   â”œâ”€â”€ eval_narrativeqa.sh
â”‚   â”œâ”€â”€ eval_locomo.sh
â”‚   â”œâ”€â”€ eval_ruler.sh
â”‚   â””â”€â”€ eval_all.sh
â”œâ”€â”€ examples/                     # Usage examples
â”‚   â””â”€â”€ quickstart/              # Quick start examples
â”‚       â”œâ”€â”€ README.md            # Examples documentation
â”‚       â”œâ”€â”€ basic_usage.py       # Basic usage example
â”‚       â””â”€â”€ model_usage.py       # Model selection example
â”œâ”€â”€ assets/                       # Resource files
â”œâ”€â”€ docs/                         # Documentation
â”œâ”€â”€ setup.py                      # Installation config
â”œâ”€â”€ pyproject.toml               # Modern project config
â”œâ”€â”€ requirements.txt             # Dependencies
â””â”€â”€ README.md                    # This file
```

<span id='quick-start'/>

## ğŸ¯ Quick Start

### ğŸš€ Installation

```bash
# Clone the repository
git clone https://github.com/VectorSpaceLab/general-agentic-memory.git
cd general-agentic-memory

# Install dependencies
pip install -r requirements.txt

# Install the package
pip install -e .
```

### ğŸ’¡ Basic Usage

```python
import os
from gam import (
    MemoryAgent,
    ResearchAgent,
    OpenAIGenerator,
    OpenAIGeneratorConfig,
    InMemoryMemoryStore,
    InMemoryPageStore,
    DenseRetrieverConfig,
    DenseRetriever,
    IndexRetrieverConfig,
    IndexRetriever,
    BM25RetrieverConfig,
    BM25Retriever
)

# 1. Configure and create generator
gen_config = OpenAIGeneratorConfig(
    model_name="gpt-4o-mini",
    api_key=os.getenv("OPENAI_API_KEY"),
    base_url="https://api.openai.com/v1",
    temperature=0.3,
    max_tokens = 256
)
generator = OpenAIGenerator.from_config(gen_config)

# 2. Create memory and page stores
memory_store = InMemoryMemoryStore()
page_store = InMemoryPageStore()

# 3. Create MemoryAgent
memory_agent = MemoryAgent(
    generator=generator,
    memory_store=memory_store,
    page_store=page_store
)

# 4. Memorize documents
documents = [
    "Artificial Intelligence is a branch of computer science...",
    "Machine Learning is a subset of AI...",
    "Deep Learning uses neural networks..."
]

for doc in documents:
    memory_agent.memorize(doc)

# 5. Get memory state
memory_state = memory_store.load()
print(f"Built {len(memory_state.abstracts)} memory abstracts")

# 6. Create ResearchAgent for Q&A

retrievers={}
index_dir = './tmp'
try:
    page_index_dir = os.path.join(index_dir, "page_index")
    if os.path.exists(page_index_dir):
        import shutil
        shutil.rmtree(page_index_dir)
    
    index_config = IndexRetrieverConfig(
        index_dir=page_index_dir
    )
    index_retriever = IndexRetriever(index_config.__dict__)
    index_retriever.build(page_store)
    retrievers["page_index"] = index_retriever
except Exception as e:
    print(f"[WARN] page retriever error: {e}")

try:
    bm25_index_dir = os.path.join(index_dir, "bm25_index")
    if os.path.exists(bm25_index_dir):
        import shutil
        shutil.rmtree(bm25_index_dir)
    
    bm25_config = BM25RetrieverConfig(
        index_dir=bm25_index_dir,
        threads=1
    )
    bm25_retriever = BM25Retriever(bm25_config.__dict__)
    bm25_retriever.build(page_store)
    retrievers["keyword"] = bm25_retriever
except Exception as e:
    print(f"[WARN] BM25 retriever error: {e}")

try:
    dense_index_dir = os.path.join(index_dir, "dense_index")
    if os.path.exists(dense_index_dir):
        import shutil
        shutil.rmtree(dense_index_dir)
    
    dense_config = DenseRetrieverConfig(
        index_dir=dense_index_dir,
        model_name="BAAI/bge-m3"
    )
    dense_retriever = DenseRetriever(dense_config.__dict__)
    dense_retriever.build(page_store)
    retrievers["vector"] = dense_retriever
except Exception as e:
    print(f"[WARN] Dense retriever error: {e}")

research_agent_kwargs = {
    "page_store": page_store,
    "memory_store": memory_store,
    "retrievers": retrievers,
    "generator": generator,
    "max_iters": 5
}

research_agent = ResearchAgent(**research_agent_kwargs)

# 7. Perform research
research_result = research_agent.research(
    request="What is the difference between ML and DL?"
)

research_summary = research_result.integrated_memory


print(f"[OK] Research completed! Iteration count: {len(research_result.raw_memory.get('iterations', []))}")
print(f"Research Summary: {research_summary}")
```

### ğŸ“š Complete Examples

For detailed examples and advanced usage:
- [`examples/quickstart/basic_usage.py`](./examples/quickstart/basic_usage.py) - Complete workflow with memory building and research
- [`examples/quickstart/model_usage.py`](./examples/quickstart/model_usage.py) - Model selection and configuration
- [`examples/quickstart/README.md`](./examples/quickstart/README.md) - Examples documentation

<span id='reproduce'/>

## ğŸ”¬ How to Reproduce the Results in the Paper

We provide a complete evaluation framework to reproduce the experimental results in the paper.

### Datasets

Because the datasets are large, they are **not** stored in this repository.  
Please download them from the original sources and place them under the `data/` directory as follows:

- **LoCoMo**

  - Download `locomo10.json` from  
    https://github.com/snap-research/locomo/blob/main/data/locomo10.json  
  - Save it as:
    - `data/locomo10.json`  

- **HotpotQA**

  - Download the following files from  
    https://huggingface.co/datasets/BytedTsinghua-SIA/hotpotqa/tree/main  
    - `eval_400.json`  
    - `eval_1600.json`  
    - `eval_3200.json`  
  - Place them under:
    - `data/hotpotqa/`  
      (or pass the exact file you want to evaluate via `--data-path`)

- **RULER**

  - Download the `data` folder from  
    https://huggingface.co/datasets/lighteval/RULER-131072-Qwen2.5-Instruct/tree/main  
  - Place it under:
    - `data/ruler/`  

- **NarrativeQA**

  - Download the `data` folder from  
    https://huggingface.co/datasets/deepmind/narrativeqa/tree/main  
  - Place it under:
    - `data/narrativeqa/`

### Quick Start

```bash
# 1. Prepare datasets
mkdir -p data
# Download the datasets from the links above and place them under data/
# following the suggested directory structure.
bash scripts/download_data.sh

# 2. Set environment variables
export OPENAI_API_KEY="your_api_key_here"

# 3. Run evaluations

# HotpotQA
# (adjust --data-path according to which split you want to use, e.g. data/hotpotqa/eval_400.json)
bash scripts/eval_hotpotqa.sh

# NarrativeQA
bash scripts/eval_narrativeqa.sh

# LoCoMo
bash scripts/eval_locomo.sh

# RULER
bash scripts/eval_ruler.sh
```

### Using Python Directly

You can also run the evaluation scripts directly:

```bash
# HotpotQA
python eval/hotpotqa_test.py \
    --data data/hotpotqa/eval_400.json \
    --outdir ./results/hotpotqa \
    --memory-api-key $OPENAI_API_KEY \
    --memory-model gpt-4o-mini \
    --research-api-key $OPENAI_API_KEY \
    --research-model gpt-4o-mini \
    --working-api-key $OPENAI_API_KEY \
    --working-model gpt-4o-mini \
    --embedding-model-path BAAI/bge-m3

# NarrativeQA
python eval/narrativeqa_test.py \
    --data-dir data/narrativeqa \
    --split test \
    --outdir ./results/narrativeqa \
    --memory-api-key $OPENAI_API_KEY \
    --memory-model gpt-4o-mini \
    --research-api-key $OPENAI_API_KEY \
    --research-model gpt-4o-mini \
    --working-api-key $OPENAI_API_KEY \
    --working-model gpt-4o-mini \
    --embedding-model-path BAAI/bge-m3

# LoCoMo
python eval/locomo_test.py \
    --data data/locomo10.json \
    --outdir ./results/locomo \
    --memory-api-key $OPENAI_API_KEY \
    --memory-model gpt-4o-mini \
    --research-api-key $OPENAI_API_KEY \
    --research-model gpt-4o-mini \
    --working-api-key $OPENAI_API_KEY \
    --working-model gpt-4o-mini

# RULER
python eval/ruler_test.py \
    --data data/ruler/qa_1.jsonl \
    --outdir ./results/ruler/qa_1 \
    --memory-api-key $OPENAI_API_KEY \
    --memory-model gpt-4o-mini \
    --research-api-key $OPENAI_API_KEY \
    --research-model gpt-4o-mini \
    --working-api-key $OPENAI_API_KEY \
    --working-model gpt-4o-mini \
    --embedding-model-path BAAI/bge-m3
```

### Supported Datasets

| Dataset | Task Type | Metrics | Script |
|---------|-----------|---------|--------|
| **HotpotQA** | Multi-hop QA | F1 | [eval/hotpotqa_test.py](./eval/hotpotqa_test.py) |
| **NarrativeQA** | Narrative QA | F1 | [eval/narrativeqa_test.py](./eval/narrativeqa_test.py) |
| **LoCoMo** | Conversation Memory | F1, BLEU-1 | [eval/locomo_test.py](./eval/locomo_test.py) |
| **RULER** | Long Context | Accuracy | [eval/ruler_test.py](./eval/ruler_test.py) |

<span id='doc'/>

## ğŸ“– Documentation

More detailed documentation is coming soon ğŸš€. Check these resources in the meantime:

- [Examples Documentation](./examples/quickstart/README.md) - Usage examples and tutorials
- [Evaluation Scripts](./eval/) - Direct evaluation scripts for each dataset

<span id='cite'/>

## ğŸ“£ Citation

**If you find this project useful, please consider citing our paper:**

```bibtex
@article{yan2025general,
  title={General Agentic Memory Via Deep Research},
  author={Yan, BY and Li, Chaofan and Qian, Hongjin and Lu, Shuqi and Liu, Zheng},
  journal={arXiv preprint arXiv:2511.18423},
  year={2025}
}
```

<span id='community'/>

## ğŸ¤ Community

### ğŸ¯ Contact Us

- GitHub Issues: [Report bugs or request features](https://github.com/VectorSpaceLab/general-agentic-memory/issues)
- Email: zhengliu1026@gmail.com

### ğŸŒŸ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=VectorSpaceLab/general-agentic-memory&type=Date)](https://star-history.com/#VectorSpaceLab/general-agentic-memory&Date)

### ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit issues or pull requests.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

We thank the authors of the following datasets:
- HotpotQA
- NarrativeQA
- LoCoMo
- RULER

## Disclaimer

This is a research project. Please use it responsibly and ethically.

---

<p align="center">
Made with â¤ï¸ by the GAM Team
</p>
